2025-09-05 11:13:18,101 - SecurityQueryAssistant.Debug - INFO - === INITIALIZING SECURITY QUERY ASSISTANT ===
2025-09-05 11:13:18,101 - SecurityQueryAssistant.Debug - INFO - Database path: personal_diary_streamlit.db
2025-09-05 11:13:18,101 - SecurityQueryAssistant.Debug - INFO - Initializing Memori with PostgreSQL database...
2025-09-05 11:13:18,101 - SecurityQueryAssistant.Debug - INFO - Database connection string: postgresql+psycopg2://pgkhang:zutSRYn6NRBS@192.168...
2025-09-05 11:13:18,839 - SecurityQueryAssistant.Debug - INFO - Enabling memory tracking...
2025-09-05 11:13:18,841 - asyncio - DEBUG - Using selector: SelectSelector
2025-09-05 11:13:18,841 - SecurityQueryAssistant.Debug - INFO - Memory tool created successfully
2025-09-05 11:13:18,844 - SecurityQueryAssistant.Debug - INFO - Model configuration: {'endpoint': 'http://your-model-endpoint.com/convert', 'api_key': 'ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm', 'timeout': 30}
2025-09-05 11:13:18,844 - SecurityQueryAssistant.Debug - INFO - === INITIALIZATION COMPLETE ===
2025-09-05 11:13:32,410 - SecurityQueryAssistant.Debug - INFO - === CHAT WITH MEMORY STARTED ===
2025-09-05 11:13:32,410 - SecurityQueryAssistant.Debug - INFO - User input: 'search logs of tenant d0034'
2025-09-05 11:13:32,410 - SecurityQueryAssistant.Debug - INFO - Mode: converter
2025-09-05 11:13:32,410 - SecurityQueryAssistant.Debug - INFO - Current conversation history length: 0
2025-09-05 11:13:32,410 - SecurityQueryAssistant.Debug - DEBUG - Initializing conversation history
2025-09-05 11:13:32,410 - SecurityQueryAssistant.Debug - DEBUG - Added user message, new history length: 2
2025-09-05 11:13:32,410 - SecurityQueryAssistant.Debug - DEBUG - Making primary LLM call with function calling...
2025-09-05 11:13:32,420 - LiteLLM - DEBUG - 

2025-09-05 11:13:32,420 - LiteLLM - DEBUG - [92mRequest to litellm:[0m
2025-09-05 11:13:32,420 - LiteLLM - DEBUG - [92mlitellm.completion(model='ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm', messages=[{'role': 'system', 'content': "You are an expert security analyst and query translator with advanced memory capabilities.\n                Your role is to help users convert natural language security queries into structured application queries\n                like graylog format. Use memory_search to understand the user's query patterns,\n                preferences, and past conversions. Be precise, learn from corrections, and provide accurate translations."}, {'role': 'user', 'content': 'search logs of tenant d0034'}], tools=[{'type': 'function', 'function': {'name': 'memory_search', 'description': 'Search memories for relevant information about past queries, patterns, corrections, and user preferences', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': "Search query to find relevant memories (e.g., 'network queries', 'splunk format preferences', 'correction patterns')"}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'convert_to_query', 'description': 'Convert natural language to structured security query using fine-tuned model', 'parameters': {'type': 'object', 'properties': {'natural_language': {'type': 'string', 'description': 'Natural language security query to convert'}, 'output_format': {'type': 'string', 'description': 'Desired output format for the query'}, 'context': {'type': 'string', 'description': 'Additional context or constraints for the conversion'}}, 'required': ['natural_language']}}}, {'type': 'function', 'function': {'name': 'analyze_query_patterns', 'description': "Analyze patterns in user's query conversion history", 'parameters': {'type': 'object', 'properties': {'analysis_type': {'type': 'string', 'enum': ['accuracy', 'formats', 'complexity', 'topics', 'improvements', 'overall'], 'description': 'Type of analysis to perform'}, 'time_period': {'type': 'string', 'enum': ['day', 'week', 'month', 'quarter', 'all_time'], 'description': 'Time period for analysis'}}, 'required': ['analysis_type']}}}, {'type': 'function', 'function': {'name': 'get_query_suggestions', 'description': "Generate personalized query suggestions based on user's history", 'parameters': {'type': 'object', 'properties': {'query_type': {'type': 'string', 'enum': ['network', 'process', 'file', 'user', 'malware', 'general'], 'description': 'Type of security query to get suggestions for'}}, 'required': ['query_type']}}}], tool_choice='auto')[0m
2025-09-05 11:13:32,420 - LiteLLM - DEBUG - 

2025-09-05 11:13:32,421 - LiteLLM - DEBUG - self.optional_params: {}
2025-09-05 11:13:32,421 - LiteLLM - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-09-05 11:13:32,427 - LiteLLM - INFO - 
LiteLLM completion() model= ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm; provider = openai
2025-09-05 11:13:32,428 - LiteLLM - DEBUG - 
LiteLLM: Params passed to completion() {'model': 'ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm', 'functions': None, 'function_call': None, 'temperature': None, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': [{'type': 'function', 'function': {'name': 'memory_search', 'description': 'Search memories for relevant information about past queries, patterns, corrections, and user preferences', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': "Search query to find relevant memories (e.g., 'network queries', 'splunk format preferences', 'correction patterns')"}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'convert_to_query', 'description': 'Convert natural language to structured security query using fine-tuned model', 'parameters': {'type': 'object', 'properties': {'natural_language': {'type': 'string', 'description': 'Natural language security query to convert'}, 'output_format': {'type': 'string', 'description': 'Desired output format for the query'}, 'context': {'type': 'string', 'description': 'Additional context or constraints for the conversion'}}, 'required': ['natural_language']}}}, {'type': 'function', 'function': {'name': 'analyze_query_patterns', 'description': "Analyze patterns in user's query conversion history", 'parameters': {'type': 'object', 'properties': {'analysis_type': {'type': 'string', 'enum': ['accuracy', 'formats', 'complexity', 'topics', 'improvements', 'overall'], 'description': 'Type of analysis to perform'}, 'time_period': {'type': 'string', 'enum': ['day', 'week', 'month', 'quarter', 'all_time'], 'description': 'Time period for analysis'}}, 'required': ['analysis_type']}}}, {'type': 'function', 'function': {'name': 'get_query_suggestions', 'description': "Generate personalized query suggestions based on user's history", 'parameters': {'type': 'object', 'properties': {'query_type': {'type': 'string', 'enum': ['network', 'process', 'file', 'user', 'malware', 'general'], 'description': 'Type of security query to get suggestions for'}}, 'required': ['query_type']}}}], 'tool_choice': 'auto', 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': "You are an expert security analyst and query translator with advanced memory capabilities.\n                Your role is to help users convert natural language security queries into structured application queries\n                like graylog format. Use memory_search to understand the user's query patterns,\n                preferences, and past conversions. Be precise, learn from corrections, and provide accurate translations."}, {'role': 'user', 'content': 'search logs of tenant d0034'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None}
2025-09-05 11:13:32,429 - LiteLLM - DEBUG - 
LiteLLM: Non-Default params passed to completion() {'tools': [{'type': 'function', 'function': {'name': 'memory_search', 'description': 'Search memories for relevant information about past queries, patterns, corrections, and user preferences', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': "Search query to find relevant memories (e.g., 'network queries', 'splunk format preferences', 'correction patterns')"}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'convert_to_query', 'description': 'Convert natural language to structured security query using fine-tuned model', 'parameters': {'type': 'object', 'properties': {'natural_language': {'type': 'string', 'description': 'Natural language security query to convert'}, 'output_format': {'type': 'string', 'description': 'Desired output format for the query'}, 'context': {'type': 'string', 'description': 'Additional context or constraints for the conversion'}}, 'required': ['natural_language']}}}, {'type': 'function', 'function': {'name': 'analyze_query_patterns', 'description': "Analyze patterns in user's query conversion history", 'parameters': {'type': 'object', 'properties': {'analysis_type': {'type': 'string', 'enum': ['accuracy', 'formats', 'complexity', 'topics', 'improvements', 'overall'], 'description': 'Type of analysis to perform'}, 'time_period': {'type': 'string', 'enum': ['day', 'week', 'month', 'quarter', 'all_time'], 'description': 'Time period for analysis'}}, 'required': ['analysis_type']}}}, {'type': 'function', 'function': {'name': 'get_query_suggestions', 'description': "Generate personalized query suggestions based on user's history", 'parameters': {'type': 'object', 'properties': {'query_type': {'type': 'string', 'enum': ['network', 'process', 'file', 'user', 'malware', 'general'], 'description': 'Type of security query to get suggestions for'}}, 'required': ['query_type']}}}], 'tool_choice': 'auto'}
2025-09-05 11:13:32,429 - LiteLLM - DEBUG - Final returned optional params: {'tools': [{'type': 'function', 'function': {'name': 'memory_search', 'description': 'Search memories for relevant information about past queries, patterns, corrections, and user preferences', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': "Search query to find relevant memories (e.g., 'network queries', 'splunk format preferences', 'correction patterns')"}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'convert_to_query', 'description': 'Convert natural language to structured security query using fine-tuned model', 'parameters': {'type': 'object', 'properties': {'natural_language': {'type': 'string', 'description': 'Natural language security query to convert'}, 'output_format': {'type': 'string', 'description': 'Desired output format for the query'}, 'context': {'type': 'string', 'description': 'Additional context or constraints for the conversion'}}, 'required': ['natural_language']}}}, {'type': 'function', 'function': {'name': 'analyze_query_patterns', 'description': "Analyze patterns in user's query conversion history", 'parameters': {'type': 'object', 'properties': {'analysis_type': {'type': 'string', 'enum': ['accuracy', 'formats', 'complexity', 'topics', 'improvements', 'overall'], 'description': 'Type of analysis to perform'}, 'time_period': {'type': 'string', 'enum': ['day', 'week', 'month', 'quarter', 'all_time'], 'description': 'Time period for analysis'}}, 'required': ['analysis_type']}}}, {'type': 'function', 'function': {'name': 'get_query_suggestions', 'description': "Generate personalized query suggestions based on user's history", 'parameters': {'type': 'object', 'properties': {'query_type': {'type': 'string', 'enum': ['network', 'process', 'file', 'user', 'malware', 'general'], 'description': 'Type of security query to get suggestions for'}}, 'required': ['query_type']}}}], 'tool_choice': 'auto', 'extra_body': {}}
2025-09-05 11:13:32,429 - LiteLLM - DEBUG - self.optional_params: {'tools': [{'type': 'function', 'function': {'name': 'memory_search', 'description': 'Search memories for relevant information about past queries, patterns, corrections, and user preferences', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': "Search query to find relevant memories (e.g., 'network queries', 'splunk format preferences', 'correction patterns')"}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'convert_to_query', 'description': 'Convert natural language to structured security query using fine-tuned model', 'parameters': {'type': 'object', 'properties': {'natural_language': {'type': 'string', 'description': 'Natural language security query to convert'}, 'output_format': {'type': 'string', 'description': 'Desired output format for the query'}, 'context': {'type': 'string', 'description': 'Additional context or constraints for the conversion'}}, 'required': ['natural_language']}}}, {'type': 'function', 'function': {'name': 'analyze_query_patterns', 'description': "Analyze patterns in user's query conversion history", 'parameters': {'type': 'object', 'properties': {'analysis_type': {'type': 'string', 'enum': ['accuracy', 'formats', 'complexity', 'topics', 'improvements', 'overall'], 'description': 'Type of analysis to perform'}, 'time_period': {'type': 'string', 'enum': ['day', 'week', 'month', 'quarter', 'all_time'], 'description': 'Time period for analysis'}}, 'required': ['analysis_type']}}}, {'type': 'function', 'function': {'name': 'get_query_suggestions', 'description': "Generate personalized query suggestions based on user's history", 'parameters': {'type': 'object', 'properties': {'query_type': {'type': 'string', 'enum': ['network', 'process', 'file', 'user', 'malware', 'general'], 'description': 'Type of security query to get suggestions for'}}, 'required': ['query_type']}}}], 'tool_choice': 'auto', 'extra_body': {}}
2025-09-05 11:13:32,430 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm', 'combined_model_name': 'openai/ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm', 'stripped_model_name': 'ft:gpt-4.1-mini-2025-04-14', 'combined_stripped_model_name': 'openai/ft:gpt-4.1-mini-2025-04-14', 'custom_llm_provider': 'openai'}
2025-09-05 11:13:32,430 - LiteLLM - DEBUG - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
2025-09-05 11:13:32,430 - LiteLLM - DEBUG - Error getting model info: This model isn't mapped yet. model=ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
2025-09-05 11:13:32,640 - LiteLLM - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.openai.com/v1/ \
-d '{'model': 'ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm', 'messages': [{'role': 'system', 'content': "You are an expert security analyst and query translator with advanced memory capabilities.\n                Your role is to help users convert natural language security queries into structured application queries\n                like graylog format. Use memory_search to understand the user's query patterns,\n                preferences, and past conversions. Be precise, learn from corrections, and provide accurate translations."}, {'role': 'user', 'content': 'search logs of tenant d0034'}], 'tools': [{'type': 'function', 'function': {'name': 'memory_search', 'description': 'Search memories for relevant information about past queries, patterns, corrections, and user preferences', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': "Search query to find relevant memories (e.g., 'network queries', 'splunk format preferences', 'correction patterns')"}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'convert_to_query', 'description': 'Convert natural language to structured security query using fine-tuned model', 'parameters': {'type': 'object', 'properties': {'natural_language': {'type': 'string', 'description': 'Natural language security query to convert'}, 'output_format': {'type': 'string', 'description': 'Desired output format for the query'}, 'context': {'type': 'string', 'description': 'Additional context or constraints for the conversion'}}, 'required': ['natural_language']}}}, {'type': 'function', 'function': {'name': 'analyze_query_patterns', 'description': "Analyze patterns in user's query conversion history", 'parameters': {'type': 'object', 'properties': {'analysis_type': {'type': 'string', 'enum': ['accuracy', 'formats', 'complexity', 'topics', 'improvements', 'overall'], 'description': 'Type of analysis to perform'}, 'time_period': {'type': 'string', 'enum': ['day', 'week', 'month', 'quarter', 'all_time'], 'description': 'Time period for analysis'}}, 'required': ['analysis_type']}}}, {'type': 'function', 'function': {'name': 'get_query_suggestions', 'description': "Generate personalized query suggestions based on user's history", 'parameters': {'type': 'object', 'properties': {'query_type': {'type': 'string', 'enum': ['network', 'process', 'file', 'user', 'malware', 'general'], 'description': 'Type of security query to get suggestions for'}}, 'required': ['query_type']}}}], 'tool_choice': 'auto', 'extra_body': {}}'
[0m

2025-09-05 11:13:32,850 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-05 11:13:32,850 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-05 11:13:32,920 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002408B8FBD10>
2025-09-05 11:13:32,920 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002408B322570> server_hostname='api.openai.com' timeout=5.0
2025-09-05 11:13:32,958 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002408BBB9810>
2025-09-05 11:13:32,958 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-05 11:13:32,958 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-05 11:13:32,958 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-05 11:13:32,958 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-05 11:13:32,958 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-05 11:13:34,038 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 05 Sep 2025 04:13:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jdt1wwaab0yepol9kzp3cxak'), (b'openai-processing-ms', b'741'), (b'openai-project', b'proj_vUUO3JuQBOeo7BsPPnZP8Zzc'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'755'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449535'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-request-id', b'req_bfb9b1a940c046c6871304c56f34fb99'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=tdEM.VQU092ON44Slv81LLLaDTLjtCcFTnY5G3KTtcs-1757045612-1.0.1.1-k0B6T1CTHXkIyS66pngDnIUhKY7KM4WAZ6bBu_m1rxLjtu6xy1ajMRWre6hg9JXm82hD2Ondtvs87Txjd6snKJK9bA2sb6hjt1fSDNChcdE; path=/; expires=Fri, 05-Sep-25 04:43:32 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=d7PzqJxUvYlxYg26woZhqVyXl9cuc1zTiUanr.v1d.4-1757045612258-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97a2e4fe198184e5-HKG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-05 11:13:34,038 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-05 11:13:34,038 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-05 11:13:34,038 - httpcore.http11 - DEBUG - response_closed.started
2025-09-05 11:13:34,038 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-05 11:13:34,038 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Fri, 05 Sep 2025 04:13:32 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jdt1wwaab0yepol9kzp3cxak'), ('openai-processing-ms', '741'), ('openai-project', 'proj_vUUO3JuQBOeo7BsPPnZP8Zzc'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '755'), ('x-ratelimit-limit-requests', '5000'), ('x-ratelimit-limit-tokens', '450000'), ('x-ratelimit-remaining-requests', '4999'), ('x-ratelimit-remaining-tokens', '449535'), ('x-ratelimit-reset-requests', '12ms'), ('x-ratelimit-reset-tokens', '61ms'), ('x-request-id', 'req_bfb9b1a940c046c6871304c56f34fb99'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=tdEM.VQU092ON44Slv81LLLaDTLjtCcFTnY5G3KTtcs-1757045612-1.0.1.1-k0B6T1CTHXkIyS66pngDnIUhKY7KM4WAZ6bBu_m1rxLjtu6xy1ajMRWre6hg9JXm82hD2Ondtvs87Txjd6snKJK9bA2sb6hjt1fSDNChcdE; path=/; expires=Fri, 05-Sep-25 04:43:32 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=d7PzqJxUvYlxYg26woZhqVyXl9cuc1zTiUanr.v1d.4-1757045612258-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '97a2e4fe198184e5-HKG'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-09-05 11:13:34,038 - openai._base_client - DEBUG - request_id: req_bfb9b1a940c046c6871304c56f34fb99
2025-09-05 11:13:34,082 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'idempotency_key': 'stainless-python-retry-301eafe0-107d-4bea-b28c-46e140709c92', 'json_data': {'messages': [{'role': 'system', 'content': "--- Relevant Memory Context ---\n- User requested log search for tenant 'd0034'; assistant provided Graylog query guidance.\n-------------------------\n\n--- Conversation History ---\nUser: search logs of tenant d0034\n--- End History ---\n\nYou are an expert security analyst and query translator with advanced memory capabilities.\n                Your role is to help users convert natural language security queries into structured application queries\n                like graylog format. Use memory_search to understand the user's query patterns,\n                preferences, and past conversions. Be precise, learn from corrections, and provide accurate translations."}, {'role': 'user', 'content': 'search logs of tenant d0034'}], 'model': 'ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm', 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'memory_search', 'description': 'Search memories for relevant information about past queries, patterns, corrections, and user preferences', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': "Search query to find relevant memories (e.g., 'network queries', 'splunk format preferences', 'correction patterns')"}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'convert_to_query', 'description': 'Convert natural language to structured security query using fine-tuned model', 'parameters': {'type': 'object', 'properties': {'natural_language': {'type': 'string', 'description': 'Natural language security query to convert'}, 'output_format': {'type': 'string', 'description': 'Desired output format for the query'}, 'context': {'type': 'string', 'description': 'Additional context or constraints for the conversion'}}, 'required': ['natural_language']}}}, {'type': 'function', 'function': {'name': 'analyze_query_patterns', 'description': "Analyze patterns in user's query conversion history", 'parameters': {'type': 'object', 'properties': {'analysis_type': {'type': 'string', 'enum': ['accuracy', 'formats', 'complexity', 'topics', 'improvements', 'overall'], 'description': 'Type of analysis to perform'}, 'time_period': {'type': 'string', 'enum': ['day', 'week', 'month', 'quarter', 'all_time'], 'description': 'Time period for analysis'}}, 'required': ['analysis_type']}}}, {'type': 'function', 'function': {'name': 'get_query_suggestions', 'description': "Generate personalized query suggestions based on user's history", 'parameters': {'type': 'object', 'properties': {'query_type': {'type': 'string', 'enum': ['network', 'process', 'file', 'user', 'malware', 'general'], 'description': 'Type of security query to get suggestions for'}}, 'required': ['query_type']}}}]}, 'extra_json': {}}
2025-09-05 11:13:34,083 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-05 11:13:34,083 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=600.0 socket_options=None
2025-09-05 11:13:34,114 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002408BBFDC10>
2025-09-05 11:13:34,114 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000240EA07F6E0> server_hostname='api.openai.com' timeout=600.0
2025-09-05 11:13:34,153 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002408BBFCB90>
2025-09-05 11:13:34,153 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-05 11:13:34,153 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-05 11:13:34,153 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-05 11:13:34,153 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-05 11:13:34,153 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-05 11:13:36,719 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 05 Sep 2025 04:13:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jdt1wwaab0yepol9kzp3cxak'), (b'openai-processing-ms', b'2165'), (b'openai-project', b'proj_vUUO3JuQBOeo7BsPPnZP8Zzc'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2172'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'1999823'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'5ms'), (b'x-request-id', b'req_aa41aa960bc54209b76387d5ebfa6e19'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=6ig1sPOayvMMpUVeeRUGirjhuHL3O4GBDqUb2FwOeOc-1757045614-1.0.1.1-DpDBlm8rbXiC.A7H_0tVFFgam9okOKMvthHzBQ0EHIQ9_a7xgLGAr4CjbTi9hUrjPQUBVTmGBPqQmcj5rrLLAGWvQDx0M7OQ_2TzZz6JBCI; path=/; expires=Fri, 05-Sep-25 04:43:34 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=5BOUggsziXLgKTCoMiVYKJBMfaqjkwvxULmRzWbYPdA-1757045614940-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97a2e5059993c1c0-HKG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-05 11:13:36,719 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-05 11:13:36,719 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-05 11:13:36,719 - httpcore.http11 - DEBUG - response_closed.started
2025-09-05 11:13:36,719 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-05 11:13:36,719 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Fri, 05 Sep 2025 04:13:34 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jdt1wwaab0yepol9kzp3cxak'), ('openai-processing-ms', '2165'), ('openai-project', 'proj_vUUO3JuQBOeo7BsPPnZP8Zzc'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '2172'), ('x-ratelimit-limit-requests', '5000'), ('x-ratelimit-limit-tokens', '2000000'), ('x-ratelimit-remaining-requests', '4999'), ('x-ratelimit-remaining-tokens', '1999823'), ('x-ratelimit-reset-requests', '12ms'), ('x-ratelimit-reset-tokens', '5ms'), ('x-request-id', 'req_aa41aa960bc54209b76387d5ebfa6e19'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=6ig1sPOayvMMpUVeeRUGirjhuHL3O4GBDqUb2FwOeOc-1757045614-1.0.1.1-DpDBlm8rbXiC.A7H_0tVFFgam9okOKMvthHzBQ0EHIQ9_a7xgLGAr4CjbTi9hUrjPQUBVTmGBPqQmcj5rrLLAGWvQDx0M7OQ_2TzZz6JBCI; path=/; expires=Fri, 05-Sep-25 04:43:34 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=5BOUggsziXLgKTCoMiVYKJBMfaqjkwvxULmRzWbYPdA-1757045614940-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '97a2e5059993c1c0-HKG'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-09-05 11:13:36,719 - openai._base_client - DEBUG - request_id: req_aa41aa960bc54209b76387d5ebfa6e19
2025-09-05 11:13:36,749 - asyncio - DEBUG - Using selector: SelectSelector
2025-09-05 11:13:36,749 - asyncio - DEBUG - Using selector: SelectSelector
2025-09-05 11:13:36,752 - LiteLLM - DEBUG - RAW RESPONSE:
{"id": "chatcmpl-CCI7IBWZAzgAKpOtjUZwaskQ2rTKr", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "\"tenantname:d0034\"", "refusal": null, "role": "assistant", "annotations": [], "audio": null, "function_call": null, "tool_calls": null}}], "created": 1757045612, "model": "ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm", "object": "chat.completion", "service_tier": "default", "system_fingerprint": "fp_78b1cf521d", "usage": {"completion_tokens": 8, "prompt_tokens": 399, "total_tokens": 407, "completion_tokens_details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}}}


2025-09-05 11:13:36,754 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-09-05 11:13:36,760 - LiteLLM - DEBUG - Logging Details LiteLLM-Success Call: Cache_hit=None
2025-09-05 11:13:36,760 - LiteLLM - DEBUG - selected model name for cost calculation: openai/ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm
2025-09-05 11:13:36,760 - LiteLLM - DEBUG - selected model name for cost calculation: openai/ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm
2025-09-05 11:13:36,760 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Helper-Method': 'chat.completions.parse'}, 'files': None, 'idempotency_key': 'stainless-python-retry-f1e51a8e-067f-41c3-89c9-0791b411daf9', 'post_parser': <function AsyncCompletions.parse.<locals>.parser at 0x000002408BBA7880>, 'json_data': {'messages': [{'role': 'system', 'content': "You are an advanced Memory Processing Agent responsible for analyzing conversations and extracting structured information with intelligent classification and conscious context detection.\n\nYour primary functions:\n1. **Intelligent Classification**: Categorize memories with enhanced classification system\n2. **Conscious Context Detection**: Identify user context information for immediate promotion\n3. **Entity Extraction**: Extract comprehensive entities and keywords\n4. **Deduplication**: Identify and handle duplicate information\n5. **Context Filtering**: Determine what should be stored vs filtered out\n\n**ENHANCED CLASSIFICATION SYSTEM:**\n\n**CONSCIOUS_INFO** (Auto-promote to short-term context):\n- User's name, location, job, personal details\n- Current projects, technologies they work with\n- Preferences, work style, communication style\n- Skills, expertise, learning goals\n- Important personal context for AI interaction\n\n**ESSENTIAL**:\n- Core facts that define user's context\n- Important preferences and opinions\n- Key skills and knowledge areas\n- Critical project information\n\n**CONTEXTUAL**:\n- Current work context\n- Ongoing projects and goals\n- Environmental setup and tools\n\n**CONVERSATIONAL**:\n- Regular discussions and questions\n- Explanations and clarifications\n- Problem-solving conversations\n\n**REFERENCE**:\n- Code examples and technical references\n- Documentation and resources\n- Learning materials\n\n**PERSONAL**:\n- Life events and personal information\n- Relationships and social context\n- Personal interests and hobbies\n\n**IMPORTANCE LEVELS:**\n- **CRITICAL**: Must never be lost\n- **HIGH**: Very important for context\n- **MEDIUM**: Useful to remember\n- **LOW**: Nice to have context\n\n**CONSCIOUS CONTEXT DETECTION:**\nMark is_user_context=True for:\n- Personal identifiers (name, location, role)\n- Work context (job, company, projects)\n- Technical preferences (languages, tools, frameworks)\n- Communication style and preferences\n- Skills and expertise areas\n- Learning goals and interests\n\nSet promotion_eligible=True for memories that should be immediately available in short-term context for all future conversations.\n\n**PROCESSING RULES:**\n1. AVOID DUPLICATES: Check if similar information already exists\n2. MERGE SIMILAR: Combine related information when appropriate\n3. FILTER UNNECESSARY: Skip trivial greetings, acknowledgments\n4. EXTRACT ENTITIES: Identify people, places, technologies, projects\n5. ASSESS IMPORTANCE: Rate based on relevance to user context\n6. FLAG USER CONTEXT: Mark information for conscious promotion\n\nFocus on extracting information that would genuinely help provide better context and assistance in future conversations.\n\nEXISTING MEMORIES (for deduplication):\nUser requested log search for tenant 'd0034'; assistant provided Graylog query guidance.\nUser requested logs for tenant 'd0034'.\nSQL query for network activity from IP 192.168.1.100 provided.\nUser requested SQL query for network activity from IP 192.168.1.100.\nUser requested SQL conversion for network activity from IP 192.168.1.100.\nUser requested SQL query for tenant 'd0034' logs.\nUser requested SQL query for tenant 'd0034' logs.\nUser requested SQL query for tenant 'd0034' logs.\nUser requested SQL query for tenant 'abc' logs.\nUser requested SQL query for tenant 'abc' logs."}, {'role': 'user', 'content': 'Process this conversation for enhanced memory storage:\n\nUser: search logs of tenant d0034\nAssistant: \n\nCONVERSATION CONTEXT:\n- Session: babe00d8-a915-4f92-a87d-559b9472626a\n- Model: ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm\n- User Projects: None specified\n- Relevant Skills: None specified\n- Topic Thread: General conversation\n'}], 'model': 'gpt-4o', 'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'$defs': {'MemoryClassification': {'description': 'Enhanced memory classification for long-term storage', 'enum': ['essential', 'contextual', 'conversational', 'reference', 'personal', 'conscious-info'], 'title': 'MemoryClassification', 'type': 'string'}, 'MemoryImportanceLevel': {'description': 'Memory importance levels', 'enum': ['critical', 'high', 'medium', 'low'], 'title': 'MemoryImportanceLevel', 'type': 'string'}}, 'description': 'Enhanced long-term memory with classification and conscious context', 'properties': {'content': {'description': 'The actual memory content', 'title': 'Content', 'type': 'string'}, 'summary': {'description': 'Concise summary for search', 'title': 'Summary', 'type': 'string'}, 'classification': {'description': 'Type classification', 'enum': ['essential', 'contextual', 'conversational', 'reference', 'personal', 'conscious-info'], 'title': 'MemoryClassification', 'type': 'string'}, 'importance': {'description': 'Importance level', 'enum': ['critical', 'high', 'medium', 'low'], 'title': 'MemoryImportanceLevel', 'type': 'string'}, 'topic': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'description': 'Main topic/subject', 'title': 'Topic'}, 'entities': {'description': 'People, places, technologies mentioned', 'items': {'type': 'string'}, 'title': 'Entities', 'type': 'array'}, 'keywords': {'description': 'Key terms for search', 'items': {'type': 'string'}, 'title': 'Keywords', 'type': 'array'}, 'is_user_context': {'default': False, 'description': 'Contains user personal info', 'title': 'Is User Context', 'type': 'boolean'}, 'is_preference': {'default': False, 'description': 'User preference/opinion', 'title': 'Is Preference', 'type': 'boolean'}, 'is_skill_knowledge': {'default': False, 'description': "User's abilities/expertise", 'title': 'Is Skill Knowledge', 'type': 'boolean'}, 'is_current_project': {'default': False, 'description': 'Current work context', 'title': 'Is Current Project', 'type': 'boolean'}, 'duplicate_of': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'description': 'Links to original if duplicate', 'title': 'Duplicate Of'}, 'supersedes': {'description': 'Previous memories this replaces', 'items': {'type': 'string'}, 'title': 'Supersedes', 'type': 'array'}, 'related_memories': {'description': 'Connected memory IDs', 'items': {'type': 'string'}, 'title': 'Related Memories', 'type': 'array'}, 'conversation_id': {'description': 'Source conversation', 'title': 'Conversation Id', 'type': 'string'}, 'confidence_score': {'default': 0.8, 'description': 'AI confidence in extraction', 'title': 'Confidence Score', 'type': 'number'}, 'extraction_timestamp': {'format': 'date-time', 'title': 'Extraction Timestamp', 'type': 'string'}, 'last_accessed': {'anyOf': [{'format': 'date-time', 'type': 'string'}, {'type': 'null'}], 'title': 'Last Accessed'}, 'access_count': {'default': 0, 'title': 'Access Count', 'type': 'integer'}, 'classification_reason': {'description': 'Why this classification was chosen', 'title': 'Classification Reason', 'type': 'string'}, 'promotion_eligible': {'default': False, 'description': 'Should be promoted to short-term', 'title': 'Promotion Eligible', 'type': 'boolean'}}, 'required': ['content', 'summary', 'classification', 'importance', 'topic', 'entities', 'keywords', 'is_user_context', 'is_preference', 'is_skill_knowledge', 'is_current_project', 'duplicate_of', 'supersedes', 'related_memories', 'conversation_id', 'confidence_score', 'extraction_timestamp', 'last_accessed', 'access_count', 'classification_reason', 'promotion_eligible'], 'title': 'ProcessedLongTermMemory', 'type': 'object', 'additionalProperties': False}, 'name': 'ProcessedLongTermMemory', 'strict': True}}, 'stream': False, 'temperature': 0.1}}
2025-09-05 11:13:36,760 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm', 'combined_model_name': 'openai/ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm', 'stripped_model_name': 'ft:gpt-4.1-mini-2025-04-14', 'combined_stripped_model_name': 'openai/ft:gpt-4.1-mini-2025-04-14', 'custom_llm_provider': 'openai'}
2025-09-05 11:13:36,760 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm', 'combined_model_name': 'openai/ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm', 'stripped_model_name': 'ft:gpt-4.1-mini-2025-04-14', 'combined_stripped_model_name': 'openai/ft:gpt-4.1-mini-2025-04-14', 'custom_llm_provider': 'openai'}
2025-09-05 11:13:36,763 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-05 11:13:36,763 - LiteLLM - DEBUG - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
2025-09-05 11:13:36,763 - LiteLLM - DEBUG - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
2025-09-05 11:13:36,763 - LiteLLM - DEBUG - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=openai/ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm - This model isn't mapped yet. model=openai/ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
2025-09-05 11:13:36,763 - LiteLLM - DEBUG - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=openai/ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm - This model isn't mapped yet. model=openai/ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
2025-09-05 11:13:36,763 - LiteLLM - DEBUG - selected model name for cost calculation: ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm
2025-09-05 11:13:36,763 - LiteLLM - DEBUG - selected model name for cost calculation: ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm
2025-09-05 11:13:36,763 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm', 'combined_model_name': 'openai/ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm', 'stripped_model_name': 'ft:gpt-4.1-mini-2025-04-14', 'combined_stripped_model_name': 'openai/ft:gpt-4.1-mini-2025-04-14', 'custom_llm_provider': 'openai'}
2025-09-05 11:13:36,763 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm', 'combined_model_name': 'openai/ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm', 'stripped_model_name': 'ft:gpt-4.1-mini-2025-04-14', 'combined_stripped_model_name': 'openai/ft:gpt-4.1-mini-2025-04-14', 'custom_llm_provider': 'openai'}
2025-09-05 11:13:36,763 - LiteLLM - DEBUG - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
2025-09-05 11:13:36,763 - LiteLLM - DEBUG - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
2025-09-05 11:13:36,763 - LiteLLM - DEBUG - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm - This model isn't mapped yet. model=ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
2025-09-05 11:13:36,769 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-05 11:13:36,763 - LiteLLM - DEBUG - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm - This model isn't mapped yet. model=ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
2025-09-05 11:13:36,769 - LiteLLM - DEBUG - response_cost_failure_debug_information: {'error_str': "This model isn't mapped yet. model=ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.", 'traceback_str': 'Traceback (most recent call last):\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\utils.py", line 4809, in _get_model_info_helper\n    raise ValueError(\nValueError: This model isn\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\litellm_core_utils\\litellm_logging.py", line 1228, in _response_cost_calculator\n    response_cost = litellm.response_cost_calculator(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1037, in response_cost_calculator\n    raise e\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1021, in response_cost_calculator\n    response_cost = completion_cost(\n                    ^^^^^^^^^^^^^^^^\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 935, in completion_cost\n    raise e\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 928, in completion_cost\n    raise e\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 890, in completion_cost\n    ) = cost_per_token(\n        ^^^^^^^^^^^^^^^\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 330, in cost_per_token\n    return openai_cost_per_token(model=model, usage=usage_block)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\llms\\openai\\cost_calculation.py", line 33, in cost_per_token\n    return generic_cost_per_token(\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\litellm_core_utils\\llm_cost_calc\\utils.py", line 233, in generic_cost_per_token\n    model_info = get_model_info(model=model, custom_llm_provider=custom_llm_provider)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\utils.py", line 5020, in get_model_info\n    _model_info = _get_model_info_helper(\n                  ^^^^^^^^^^^^^^^^^^^^^^^\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\utils.py", line 4938, in _get_model_info_helper\n    raise Exception(\nException: This model isn\'t mapped yet. model=ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n', 'model': 'ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm', 'cache_hit': False, 'custom_llm_provider': 'openai', 'base_model': None, 'call_type': 'completion', 'custom_pricing': False}
2025-09-05 11:13:36,769 - LiteLLM - DEBUG - response_cost_failure_debug_information: {'error_str': "This model isn't mapped yet. model=ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.", 'traceback_str': 'Traceback (most recent call last):\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\utils.py", line 4809, in _get_model_info_helper\n    raise ValueError(\nValueError: This model isn\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\litellm_core_utils\\litellm_logging.py", line 1228, in _response_cost_calculator\n    response_cost = litellm.response_cost_calculator(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1037, in response_cost_calculator\n    raise e\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1021, in response_cost_calculator\n    response_cost = completion_cost(\n                    ^^^^^^^^^^^^^^^^\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 935, in completion_cost\n    raise e\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 928, in completion_cost\n    raise e\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 890, in completion_cost\n    ) = cost_per_token(\n        ^^^^^^^^^^^^^^^\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 330, in cost_per_token\n    return openai_cost_per_token(model=model, usage=usage_block)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\llms\\openai\\cost_calculation.py", line 33, in cost_per_token\n    return generic_cost_per_token(\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\litellm_core_utils\\llm_cost_calc\\utils.py", line 233, in generic_cost_per_token\n    model_info = get_model_info(model=model, custom_llm_provider=custom_llm_provider)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\utils.py", line 5020, in get_model_info\n    _model_info = _get_model_info_helper(\n                  ^^^^^^^^^^^^^^^^^^^^^^^\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\utils.py", line 4938, in _get_model_info_helper\n    raise Exception(\nException: This model isn\'t mapped yet. model=ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n', 'model': 'ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm', 'cache_hit': None, 'custom_llm_provider': 'openai', 'base_model': None, 'call_type': 'completion', 'custom_pricing': False}
2025-09-05 11:13:36,769 - SecurityQueryAssistant.Debug - DEBUG - Primary LLM call completed in 4.359s
2025-09-05 11:13:36,778 - SecurityQueryAssistant.Tokens - INFO - Token Usage - Model: ft, Function: chat_with_memory_primary, Input: 399, Output: 8, Duration: 4.36s, Cost: $0.000615
2025-09-05 11:13:36,769 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm', 'combined_model_name': 'openai/ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm', 'stripped_model_name': 'ft:gpt-4.1-mini-2025-04-14', 'combined_stripped_model_name': 'openai/ft:gpt-4.1-mini-2025-04-14', 'custom_llm_provider': 'openai'}
2025-09-05 11:13:36,778 - SecurityQueryAssistant.Debug - DEBUG - Response message type: <class 'litellm.types.utils.Message'>
2025-09-05 11:13:36,778 - LiteLLM - DEBUG - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
2025-09-05 11:13:36,778 - SecurityQueryAssistant.Debug - DEBUG - Tool calls count: 0
2025-09-05 11:13:36,778 - LiteLLM - DEBUG - Model=ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload
2025-09-05 11:13:36,778 - SecurityQueryAssistant.Debug - ERROR - Chat with memory failed after 4.369s: Object of type CompletionTokensDetailsWrapper is not JSON serializable
2025-09-05 11:13:36,778 - LiteLLM - DEBUG - Logging Details LiteLLM-Success Call streaming complete
2025-09-05 11:13:36,778 - LiteLLM - DEBUG - selected model name for cost calculation: openai/ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm
2025-09-05 11:13:36,780 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm', 'combined_model_name': 'openai/ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm', 'stripped_model_name': 'ft:gpt-4.1-mini-2025-04-14', 'combined_stripped_model_name': 'openai/ft:gpt-4.1-mini-2025-04-14', 'custom_llm_provider': 'openai'}
2025-09-05 11:13:36,780 - LiteLLM - DEBUG - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
2025-09-05 11:13:36,780 - LiteLLM - DEBUG - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=openai/ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm - This model isn't mapped yet. model=openai/ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
2025-09-05 11:13:36,780 - SecurityQueryAssistant.Debug - ERROR - Traceback: Traceback (most recent call last):
  File "C:\Users\kael02\IdeaProjects\memori\demos\personal_diary_assistant\diary_assistant.py", line 729, in chat_with_memory
    self._log_api_call("chat_with_memory_primary",
  File "C:\Users\kael02\IdeaProjects\memori\demos\personal_diary_assistant\diary_assistant.py", line 307, in _log_api_call
    api_logger.info(f"API Call: {json.dumps(call_info, indent=2)}")
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\json\encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\json\encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\json\encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type CompletionTokensDetailsWrapper is not JSON serializable

2025-09-05 11:13:36,780 - LiteLLM - DEBUG - selected model name for cost calculation: ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm
2025-09-05 11:13:36,780 - SecurityQueryAssistant.API - INFO - API Call: {
  "timestamp": "2025-09-05T11:13:36.780197",
  "function": "chat_with_memory",
  "parameters": {
    "user_input": "search logs of tenant d0034",
    "mode": "converter"
  },
  "duration": 4.368616580963135,
  "success": false,
  "error": "Object of type CompletionTokensDetailsWrapper is not JSON serializable",
  "error_type": "TypeError"
}
2025-09-05 11:13:36,780 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm', 'combined_model_name': 'openai/ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm', 'stripped_model_name': 'ft:gpt-4.1-mini-2025-04-14', 'combined_stripped_model_name': 'openai/ft:gpt-4.1-mini-2025-04-14', 'custom_llm_provider': 'openai'}
2025-09-05 11:13:36,780 - LiteLLM - DEBUG - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
2025-09-05 11:13:36,870 - LiteLLM - DEBUG - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm - This model isn't mapped yet. model=ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
2025-09-05 11:13:36,870 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002408B454A50>
2025-09-05 11:13:36,870 - LiteLLM - DEBUG - response_cost_failure_debug_information: {'error_str': "This model isn't mapped yet. model=ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.", 'traceback_str': 'Traceback (most recent call last):\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\utils.py", line 4809, in _get_model_info_helper\n    raise ValueError(\nValueError: This model isn\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\litellm_core_utils\\litellm_logging.py", line 1228, in _response_cost_calculator\n    response_cost = litellm.response_cost_calculator(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1037, in response_cost_calculator\n    raise e\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1021, in response_cost_calculator\n    response_cost = completion_cost(\n                    ^^^^^^^^^^^^^^^^\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 935, in completion_cost\n    raise e\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 928, in completion_cost\n    raise e\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 890, in completion_cost\n    ) = cost_per_token(\n        ^^^^^^^^^^^^^^^\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 330, in cost_per_token\n    return openai_cost_per_token(model=model, usage=usage_block)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\llms\\openai\\cost_calculation.py", line 33, in cost_per_token\n    return generic_cost_per_token(\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\litellm_core_utils\\llm_cost_calc\\utils.py", line 233, in generic_cost_per_token\n    model_info = get_model_info(model=model, custom_llm_provider=custom_llm_provider)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\utils.py", line 5020, in get_model_info\n    _model_info = _get_model_info_helper(\n                  ^^^^^^^^^^^^^^^^^^^^^^^\n  File "C:\\Users\\kael02\\IdeaProjects\\memori\\demos\\personal_diary_assistant\\venv\\Lib\\site-packages\\litellm\\utils.py", line 4938, in _get_model_info_helper\n    raise Exception(\nException: This model isn\'t mapped yet. model=ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n', 'model': 'ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm', 'cache_hit': None, 'custom_llm_provider': 'openai', 'base_model': None, 'call_type': 'completion', 'custom_pricing': False}
2025-09-05 11:13:36,878 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002408B3224E0> server_hostname='api.openai.com' timeout=5.0
2025-09-05 11:13:36,879 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm', 'combined_model_name': 'openai/ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm', 'stripped_model_name': 'ft:gpt-4.1-mini-2025-04-14', 'combined_stripped_model_name': 'openai/ft:gpt-4.1-mini-2025-04-14', 'custom_llm_provider': 'openai'}
2025-09-05 11:13:36,879 - LiteLLM - DEBUG - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
2025-09-05 11:13:36,879 - LiteLLM - DEBUG - Model=ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload
2025-09-05 11:13:36,879 - LiteLLM - DEBUG - success callbacks: Running Custom Callback Function - <bound method LiteLLMCallbackManager._litellm_success_callback of <memori.integrations.litellm_integration.LiteLLMCallbackManager object at 0x000002408B423250>>
2025-09-05 11:13:36,978 - asyncio - DEBUG - Using selector: SelectSelector
2025-09-05 11:13:36,979 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002408BC60A90>
2025-09-05 11:13:36,979 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-05 11:13:36,979 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-05 11:13:36,979 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-05 11:13:36,979 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-05 11:13:36,986 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Helper-Method': 'chat.completions.parse'}, 'files': None, 'idempotency_key': 'stainless-python-retry-e4de1a4c-2a43-4d4b-b0ed-48599a43f090', 'post_parser': <function AsyncCompletions.parse.<locals>.parser at 0x00000240EA1A7060>, 'json_data': {'messages': [{'role': 'system', 'content': "You are an advanced Memory Processing Agent responsible for analyzing conversations and extracting structured information with intelligent classification and conscious context detection.\n\nYour primary functions:\n1. **Intelligent Classification**: Categorize memories with enhanced classification system\n2. **Conscious Context Detection**: Identify user context information for immediate promotion\n3. **Entity Extraction**: Extract comprehensive entities and keywords\n4. **Deduplication**: Identify and handle duplicate information\n5. **Context Filtering**: Determine what should be stored vs filtered out\n\n**ENHANCED CLASSIFICATION SYSTEM:**\n\n**CONSCIOUS_INFO** (Auto-promote to short-term context):\n- User's name, location, job, personal details\n- Current projects, technologies they work with\n- Preferences, work style, communication style\n- Skills, expertise, learning goals\n- Important personal context for AI interaction\n\n**ESSENTIAL**:\n- Core facts that define user's context\n- Important preferences and opinions\n- Key skills and knowledge areas\n- Critical project information\n\n**CONTEXTUAL**:\n- Current work context\n- Ongoing projects and goals\n- Environmental setup and tools\n\n**CONVERSATIONAL**:\n- Regular discussions and questions\n- Explanations and clarifications\n- Problem-solving conversations\n\n**REFERENCE**:\n- Code examples and technical references\n- Documentation and resources\n- Learning materials\n\n**PERSONAL**:\n- Life events and personal information\n- Relationships and social context\n- Personal interests and hobbies\n\n**IMPORTANCE LEVELS:**\n- **CRITICAL**: Must never be lost\n- **HIGH**: Very important for context\n- **MEDIUM**: Useful to remember\n- **LOW**: Nice to have context\n\n**CONSCIOUS CONTEXT DETECTION:**\nMark is_user_context=True for:\n- Personal identifiers (name, location, role)\n- Work context (job, company, projects)\n- Technical preferences (languages, tools, frameworks)\n- Communication style and preferences\n- Skills and expertise areas\n- Learning goals and interests\n\nSet promotion_eligible=True for memories that should be immediately available in short-term context for all future conversations.\n\n**PROCESSING RULES:**\n1. AVOID DUPLICATES: Check if similar information already exists\n2. MERGE SIMILAR: Combine related information when appropriate\n3. FILTER UNNECESSARY: Skip trivial greetings, acknowledgments\n4. EXTRACT ENTITIES: Identify people, places, technologies, projects\n5. ASSESS IMPORTANCE: Rate based on relevance to user context\n6. FLAG USER CONTEXT: Mark information for conscious promotion\n\nFocus on extracting information that would genuinely help provide better context and assistance in future conversations.\n\nEXISTING MEMORIES (for deduplication):\nUser requested log search for tenant 'd0034'; assistant provided Graylog query guidance.\nUser requested logs for tenant 'd0034'.\nSQL query for network activity from IP 192.168.1.100 provided.\nUser requested SQL query for network activity from IP 192.168.1.100.\nUser requested SQL conversion for network activity from IP 192.168.1.100.\nUser requested SQL query for tenant 'd0034' logs.\nUser requested SQL query for tenant 'd0034' logs.\nUser requested SQL query for tenant 'd0034' logs.\nUser requested SQL query for tenant 'abc' logs.\nUser requested SQL query for tenant 'abc' logs."}, {'role': 'user', 'content': 'Process this conversation for enhanced memory storage:\n\nUser: search logs of tenant d0034\nAssistant: "tenantname:d0034"\n\nCONVERSATION CONTEXT:\n- Session: babe00d8-a915-4f92-a87d-559b9472626a\n- Model: ft:gpt-4.1-mini-2025-04-14:personal:gpt-mini-generator:CC22K4Xm\n- User Projects: None specified\n- Relevant Skills: None specified\n- Topic Thread: General conversation\n'}], 'model': 'gpt-4o', 'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'$defs': {'MemoryClassification': {'description': 'Enhanced memory classification for long-term storage', 'enum': ['essential', 'contextual', 'conversational', 'reference', 'personal', 'conscious-info'], 'title': 'MemoryClassification', 'type': 'string'}, 'MemoryImportanceLevel': {'description': 'Memory importance levels', 'enum': ['critical', 'high', 'medium', 'low'], 'title': 'MemoryImportanceLevel', 'type': 'string'}}, 'description': 'Enhanced long-term memory with classification and conscious context', 'properties': {'content': {'description': 'The actual memory content', 'title': 'Content', 'type': 'string'}, 'summary': {'description': 'Concise summary for search', 'title': 'Summary', 'type': 'string'}, 'classification': {'description': 'Type classification', 'enum': ['essential', 'contextual', 'conversational', 'reference', 'personal', 'conscious-info'], 'title': 'MemoryClassification', 'type': 'string'}, 'importance': {'description': 'Importance level', 'enum': ['critical', 'high', 'medium', 'low'], 'title': 'MemoryImportanceLevel', 'type': 'string'}, 'topic': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'description': 'Main topic/subject', 'title': 'Topic'}, 'entities': {'description': 'People, places, technologies mentioned', 'items': {'type': 'string'}, 'title': 'Entities', 'type': 'array'}, 'keywords': {'description': 'Key terms for search', 'items': {'type': 'string'}, 'title': 'Keywords', 'type': 'array'}, 'is_user_context': {'default': False, 'description': 'Contains user personal info', 'title': 'Is User Context', 'type': 'boolean'}, 'is_preference': {'default': False, 'description': 'User preference/opinion', 'title': 'Is Preference', 'type': 'boolean'}, 'is_skill_knowledge': {'default': False, 'description': "User's abilities/expertise", 'title': 'Is Skill Knowledge', 'type': 'boolean'}, 'is_current_project': {'default': False, 'description': 'Current work context', 'title': 'Is Current Project', 'type': 'boolean'}, 'duplicate_of': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'description': 'Links to original if duplicate', 'title': 'Duplicate Of'}, 'supersedes': {'description': 'Previous memories this replaces', 'items': {'type': 'string'}, 'title': 'Supersedes', 'type': 'array'}, 'related_memories': {'description': 'Connected memory IDs', 'items': {'type': 'string'}, 'title': 'Related Memories', 'type': 'array'}, 'conversation_id': {'description': 'Source conversation', 'title': 'Conversation Id', 'type': 'string'}, 'confidence_score': {'default': 0.8, 'description': 'AI confidence in extraction', 'title': 'Confidence Score', 'type': 'number'}, 'extraction_timestamp': {'format': 'date-time', 'title': 'Extraction Timestamp', 'type': 'string'}, 'last_accessed': {'anyOf': [{'format': 'date-time', 'type': 'string'}, {'type': 'null'}], 'title': 'Last Accessed'}, 'access_count': {'default': 0, 'title': 'Access Count', 'type': 'integer'}, 'classification_reason': {'description': 'Why this classification was chosen', 'title': 'Classification Reason', 'type': 'string'}, 'promotion_eligible': {'default': False, 'description': 'Should be promoted to short-term', 'title': 'Promotion Eligible', 'type': 'boolean'}}, 'required': ['content', 'summary', 'classification', 'importance', 'topic', 'entities', 'keywords', 'is_user_context', 'is_preference', 'is_skill_knowledge', 'is_current_project', 'duplicate_of', 'supersedes', 'related_memories', 'conversation_id', 'confidence_score', 'extraction_timestamp', 'last_accessed', 'access_count', 'classification_reason', 'promotion_eligible'], 'title': 'ProcessedLongTermMemory', 'type': 'object', 'additionalProperties': False}, 'name': 'ProcessedLongTermMemory', 'strict': True}}, 'stream': False, 'temperature': 0.1}}
2025-09-05 11:13:36,986 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-05 11:13:36,988 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-05 11:13:36,989 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-05 11:13:37,020 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002408BD4CE50>
2025-09-05 11:13:37,020 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002408B3224E0> server_hostname='api.openai.com' timeout=5.0
2025-09-05 11:13:37,060 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002408B2A8210>
2025-09-05 11:13:37,060 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-05 11:13:37,060 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-05 11:13:37,060 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-05 11:13:37,060 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-05 11:13:37,060 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-05 11:13:39,514 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 05 Sep 2025 04:13:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jdt1wwaab0yepol9kzp3cxak'), (b'openai-processing-ms', b'2214'), (b'openai-project', b'proj_vUUO3JuQBOeo7BsPPnZP8Zzc'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2217'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449087'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'121ms'), (b'x-request-id', b'req_08c6d79d4564488bbf4ba7f0a5bd33af'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=vecG3x_f2RCbuWQyoTaBs7m0acd9MDfw90ueyLVo3qE-1757045617-1.0.1.1-Sk81YDeI.lv_k5vUI.EqTvXnKzItj3zOM87FFlu9_YWCvfs3p_FOi4r9F9kMWdpC_ElTYHOAZeu58kG9frU2IdguOl3dXvaVyfsIQ5fRCoQ; path=/; expires=Fri, 05-Sep-25 04:43:37 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=T2X7YvEsWZrLgE6e4ML1LdIkvdzr9XaSOECdCsElfVs-1757045617735-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97a2e51738f004b7-HKG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-05 11:13:39,514 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-05 11:13:39,514 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-05 11:13:39,518 - httpcore.http11 - DEBUG - response_closed.started
2025-09-05 11:13:39,518 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-05 11:13:39,518 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Fri, 05 Sep 2025 04:13:37 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jdt1wwaab0yepol9kzp3cxak'), ('openai-processing-ms', '2214'), ('openai-project', 'proj_vUUO3JuQBOeo7BsPPnZP8Zzc'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '2217'), ('x-ratelimit-limit-requests', '5000'), ('x-ratelimit-limit-tokens', '450000'), ('x-ratelimit-remaining-requests', '4999'), ('x-ratelimit-remaining-tokens', '449087'), ('x-ratelimit-reset-requests', '12ms'), ('x-ratelimit-reset-tokens', '121ms'), ('x-request-id', 'req_08c6d79d4564488bbf4ba7f0a5bd33af'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=vecG3x_f2RCbuWQyoTaBs7m0acd9MDfw90ueyLVo3qE-1757045617-1.0.1.1-Sk81YDeI.lv_k5vUI.EqTvXnKzItj3zOM87FFlu9_YWCvfs3p_FOi4r9F9kMWdpC_ElTYHOAZeu58kG9frU2IdguOl3dXvaVyfsIQ5fRCoQ; path=/; expires=Fri, 05-Sep-25 04:43:37 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=T2X7YvEsWZrLgE6e4ML1LdIkvdzr9XaSOECdCsElfVs-1757045617735-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '97a2e51738f004b7-HKG'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-09-05 11:13:39,519 - openai._base_client - DEBUG - request_id: req_08c6d79d4564488bbf4ba7f0a5bd33af
2025-09-05 11:13:40,036 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 05 Sep 2025 04:13:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-jdt1wwaab0yepol9kzp3cxak'), (b'openai-processing-ms', b'2527'), (b'openai-project', b'proj_vUUO3JuQBOeo7BsPPnZP8Zzc'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2531'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449083'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'122ms'), (b'x-request-id', b'req_1e5b0e446f0345bab463cbce38b39df3'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=hSaGtvHr0Ywb89IbwD.2OHo8EUxknR1MvjWiEGjLfMM-1757045618-1.0.1.1-4AZZuWTaYXZHfEOw8sJxiVw1ubNm2RxE1uzUWQ6Ko8B_8hFbS1hvBKy5.rFnqPupQ6RwG3YKqEwwvfqfau1ctKT9LT24ewXSA.GBRoAPDjM; path=/; expires=Fri, 05-Sep-25 04:43:38 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=ewbV3boJm35ENUivxt2TRAMu0IySGg.zzbxU0uoy72U-1757045618256-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97a2e517becd0df8-HKG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-05 11:13:40,038 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-05 11:13:40,040 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-05 11:13:40,040 - httpcore.http11 - DEBUG - response_closed.started
2025-09-05 11:13:40,040 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-05 11:13:40,040 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Fri, 05 Sep 2025 04:13:38 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-jdt1wwaab0yepol9kzp3cxak'), ('openai-processing-ms', '2527'), ('openai-project', 'proj_vUUO3JuQBOeo7BsPPnZP8Zzc'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '2531'), ('x-ratelimit-limit-requests', '5000'), ('x-ratelimit-limit-tokens', '450000'), ('x-ratelimit-remaining-requests', '4999'), ('x-ratelimit-remaining-tokens', '449083'), ('x-ratelimit-reset-requests', '12ms'), ('x-ratelimit-reset-tokens', '122ms'), ('x-request-id', 'req_1e5b0e446f0345bab463cbce38b39df3'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=hSaGtvHr0Ywb89IbwD.2OHo8EUxknR1MvjWiEGjLfMM-1757045618-1.0.1.1-4AZZuWTaYXZHfEOw8sJxiVw1ubNm2RxE1uzUWQ6Ko8B_8hFbS1hvBKy5.rFnqPupQ6RwG3YKqEwwvfqfau1ctKT9LT24ewXSA.GBRoAPDjM; path=/; expires=Fri, 05-Sep-25 04:43:38 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=ewbV3boJm35ENUivxt2TRAMu0IySGg.zzbxU0uoy72U-1757045618256-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '97a2e517becd0df8-HKG'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-09-05 11:13:40,040 - openai._base_client - DEBUG - request_id: req_1e5b0e446f0345bab463cbce38b39df3
2025-09-05 11:15:15,706 - asyncio - DEBUG - Using selector: SelectSelector
